\documentclass[a4paper,10pt]{llncs}

\usepackage{graphicx}
\usepackage{multicol}
\usepackage{amsbsy,amscd,amsfonts,amssymb,amstext,amsmath,latexsym,theorem}
\usepackage{todonotes}
\usepackage{mathpartir}
\usepackage{nameref}
\usepackage{url}

\pagestyle{plain}
\bibliographystyle{alpha}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{{\normalsize Seminar: Formal Specification} \\[1ex]
  Security of Multithreaded Programs by Compilation\cite{Barthe07}}
\author{Pascal Wittmann, Advisor: Artem Starostin}
\institute{TU Darmstadt}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivation}
\label{sec:motivation}
Protecting the confidentiality of information that is processed by
a modern computer is challenging and important, since more and more sensitive
information is fed to them. Access control and encryption are not enough to
ensure this confidentiality, because the usage of the information after the
access or decryption is not restricted. It is necessary to control the
\textit{information flow} to protect the sensitive information.
On modern mobile devices sensitive information is processed and programs
are executed multithreaded (e.g. to prevent lock ups when establishing
a network connection). Through the timing difference of the scheduled threads it
is likely that sensitive information is leaked and an attack may obtain all
sensitive data.

The idea Barthe, Rezk, Russo and Sabelfeld phrased in \cite{Barthe07} was to close
this leak (more formally called \textit{covert channel}) by annotating the byte-code
of the program (most mobile devices use some sort of byte-code e.g. Android) with security
labels according to the processed information, which causes the scheduler to hide
threads that leak information from the attacker.

\section{Introduction to the research area}
\label{sec:introduction}
The challenge to protect the confidentiality of information processed by
a computer lead thirty years ago (c.f. \cite{Zdancewic04}) to the research
on the security information-flows, because of the shortcomings of the standard methods.
These standard methods are: Access control and encryption. Where
access control ensures that the data is only accessed by an authorized entity,
and encryption ensures that data can be securely transmitted over an insecure channel.
But all these methods cover the release of information and not the further
propagation (i.e. how the information is used after having access to it or decrypting
it). This is the place where information-flow security comes into play.

The idea is to 'track and regulate' \cite{Zdancewic04} where information flows to
prevent the leak of secret information. The ways on which the information flows
through the system are called channels. Channels that are not indented to transport
information are called covered channels. These covered channels can
be classified into the following categories \cite{Sabelfeld03} (in the following examples $h$ is a secret
variable and $l$ a variable that is plublic):

\begin{itemize}
\item \textit{Explicit and implicit flows}: In an explicit flow the information is leaked
      directly into some public variable (e.g. $l := h$), while in implicit flows the information
      is leaked through the control structure of the program (e.g. $\text{if}\ h = 1\ \text{then}\ l := 1\ \text{else}\ l := 0$).
\item \textit{Probabilistic channels}: If an attacker is able to run a computation multiple times
      he might be able to obtain information by looking at the probability distribution of the
      public outputs.
\item \textit{Power channels}: If the attacker has physical access to the computer or at least figure out
      the power consumption, he might be able to obtain data through the changing power consumption.
\item \textit{Resource exhausting channels}: Information also may be leaked through the exhaustion
      of finite (mostly physical) resources (e.g. a buffer overflow).
\item \textit{Termination channels}: The attacker can obtain information through the termination
      or non-termination of the computation or program.
\item \textit{Timing channels:} Information can be obtained through the time at which this action
      occurs. On the one hand \textit{external} timing channels cover the action like the termination
      of the program, where the attacker obtains information from the total execution time of the program.
      On the other hand \textit{internal} timing channels are occur in multithreaded programs through the timing difference
      between threads. For example the two threaded (denoted with $||$) program \[\text{if}\ h = 1\ \{\text{sleep}(100)\}\ ;\ l := 1\ ||\ \text{sleep}(50)\ ;\ l := 0\]
      executed with most schedulers will leak the information of $h$ into $l$ through the timing difference
      if $h = 1$.
\end{itemize}

The notion of confidentiality that is used in most work in the area of information-flow security is \textit{noninterference}.
This policy is defined in various ways but the essence is, that it requires 'that secret information
[do] not affect [the] publicly observable behavior of a system'\footnote{Even wen the attacker has full access to the
source code of the program.}\cite{Zdancewic04}. For most real world
applications this policy is far too strict, because it forbids useful programs like password checkers.\footnote{A
password checker needs to reveal whether the user input was correct or not.} Approaches that allow
controlled release of information are called declassification. The kinds of declassification are \textit{what}
information is released, \textit{who} released this information, \textit{where} in the system the information
is released and \textit{when} the information is released (c.f. \cite{Sabelfeld05}). For these approaches it is necessary that an
active attacker can only know as much as a passive attacker.

Mechanisms for controlling the information flow can be implemented either dynamic or static. The dynamic approach\footnote{
The taint mode of the programming language Perl uses this mechanism.}
labels the information with security labels and propagates these labels wherever the information is used. The static
approach\footnote{This approach is implemented in Jif for Java and Flow Caml for Caml.} analyses the program code and is
therefor far more promising, because with this approach it is possible to check all evaluation paths.

The paper resumed in the following concentrates on internal timing channels with a noninterference policy.

\section{Summary of the article}
\label{sec:discussion}
In this summary I will follow mainly the structure of the original
paper\cite{Barthe07} which is as follows. After the introduction the basic
terms and definitions for a multithreaded programs and the scheduler are
laid. After that the notion of security we want to achieve is presented.
Along with this a skeleton of a type system is described, which ensures
that a program typable in this type system is secure w.r.t the notion of
security. The proof that this holds is sketched in the following section.
In the last section the (by now) abstract framework is instantiated with a
concrete example.

\subsection{Syntax and Semantics of multithreaded programs}
\label{sec:syntaxsemantics}
A program is viewed as an abstract thing, which consists of a set of
program points $\mathcal{P}$ with a distinguished entry ($1$) and exit
(\texttt{exit}) point and a function $P$ that maps program points to
instructions.

These instructions are not further specified, but contain an instruction
to create a new thread (\texttt{start \textit{pc}} where pc is the start
instruction of the new thread).

Further, there is a relation $\mapsto$ that describes possible successor
instructions. \texttt{exit} is the only program point with no successor
and \texttt{start \textit{pc}} may only have a single successor (the
following program point).

The next thing introduced are the security levels. We assume the attacker
'is' a level $k$. From this assumption we can reduce every set of security levels
w.l.o.g into $\{low, high\}$, where $low < high$, by mapping elements
that are no more sensitive than $k$ to $low$ and all other elements
-- including incomparable ones -- to $high$. It is also assumed, that access
control works correctly (i.e. the attacker can not access $high$ elements
directly).

To connect programs and security levels, a \textit{security environment}
(se) is defined, which is used to prevent flows over implicit channels.
A security environment is a function that maps program points to security
levels. A program point $i$ is called high if $se(i) = high$, low if $se(i)
= low$ and always high if all points $j$ reachable (according to $\mapsto$)
from $i$ satisfy $se(j) = high$ and $i$ is a high program point.

Now we come to the semantics part. The main idea is to build the semantics
for multithreaded programs by combining the semantics for sequential programs
with a scheduler.

All active\footnote{A thread is active from \texttt{start \textit{pc}} until
it reaches the \texttt{exit} point.} threads are collected in a set $Thread$.
The state of the concurrent running threads ($ConcState$) is defined as the
product of the partial function space $(Thread \rightharpoonup LocState)$
and the set of global memories $GMemory$. Where $LocState$ is the internal
memory of a thread (from there no information can leak, because everything is private/internal) and the global memory $GMemory$ which is
the critical part of the system, because it is a memory shared between all
active threads.

At this point a first simplification can be made. Looking a state $s \in \text{ConcState}$ we can
first extract the active threads (\texttt{s.act}) by taking the domain of the first
component. According to a security environment we can classify these threads,
with respect to their current program point (\texttt{s.pc(tid)} where $tid \in \text{Thread}$),
into \textit{low} threads iff the current program point is low. In \textit{high}
threads iff the current program point is high. In \textit{always high} threads
iff the current program point is always high and in \textit{hidden} threads, iff
the current program point is high but not always high.

The latter two are the interesting ones. If a thread is \textit{always high} it
can not leaks any information into low, because it never gets in touch
with low program points. So these threads can safely be interleaved between any
other threads by the scheduler.

The \textit{hidden} threads are the ones we have to care about. These contain
obviously high information in the current program point, but have afterwards
instructions that deal with low information. Since the attacker can watch the
low part of the memory, chances are good that he can deduce high information
through looking at changing low outputs. To prevent indirect flows that are introduced by
these hidden threads, the scheduler will be modified to treat these threads
in a special way. This will be done by 'hiding' these threads, therefore comes
the name of them.

To complete our multithreaded setup we need a scheduler. The scheduler will
operate on histories. A history is a list of pairs $(tid, l$), where $tid \in
\text{Thread}$ and $l \in \text{Level}$. In this history all threads chosen by the scheduler
are recorded.

At this point no concrete scheduler is defined to make the framework applicable
for a wide class of schedulers. A scheduler is in this class iff it can be
modeled as a function $pickt: \text{ConcState} \times \text{History} \rightharpoonup \text{Thread}$
which satisfies the following constraints:

\begin{enumerate}
\item It always picks an active thread
\item If there is a hidden thread, always choose high or always high threads
\item Only use low information and the low part of the history to choose a
      new thread
\end{enumerate}

In constraint two the interleaving of always high threads is realized.

To define what noninterference means we need a notion of excution. It is assumed
that we have a sequential execution relation $\leadsto_{seq} \subseteq \text{SeqState} \times
\text{SeqState}$. The one step execution for the multithreaded language $\leadsto_{seq}
\subseteq (\text{ConcState} \times \text{History}) \times (\text{ConcState} \times \text{History})$ is defined
by the following rules.

\begin{figure}
\begin{align*}
\inferrule{pick(s, h) = ctid \\ s.pc(ctid) = i \\ P[i] \in \text{SeqIns} \\
\langle s(ctid), s.gmem\rangle \leadsto_{seq} \sigma,\mu \\ \sigma.pc \neq \mathtt{exit}}
{s,h \leadsto_{conc} s[lst(ctid) := \sigma, gmem := \mu], \langle ctid, se(i)\rangle :: h}
\end{align*}

\begin{align*}
\inferrule{pick(s, h) = ctid \\ s.pc(ctid) = i \\ P[i] \in \text{SeqIns} \\
\langle s(ctid), s.gmem\rangle \leadsto_{seq} \sigma,\mu \\ \sigma.pc = \mathtt{exit}}
{s,h \leadsto_{conc} s[lst := lst \\ ctid, gmem := \mu], \langle ctid, se(i)\rangle :: h}
\end{align*}

\begin{align*}
\inferrule{pick(s, h) = ctid \\ s.pc(ctid) = i \\ P[i] = \mathtt{start} pc \\
fresht_{se(i)}(s) = ntid \\ s(ctid).[pc := i + 1] = \sigma'}
{s,h \leadsto_{conc} s.[lst(ctid) := \sigma', lst(ntid) := \lambda_{init}(pc)],
\langle ctid, se(i)\rangle :: h}
\end{align*}
\caption{Multithreaded execution.}
\label{fig:multithreaded-execution}
\end{figure}

The scheduler is allow to pick a new thread after every transition of $\leadsto_{seq}$. The
intuition of the first rule is, that the scheduler picks a new thread $ctid$ which is at
program point $i$. This program point maps to an sequential instruction. The exection of
this instruction leads to a local state $\sigma$ and a global memory $\mu$. If these conditions
are met and instruction $i$ was not the last instruction (i.e. $\sigma.pc \neq \mathtt{exit}$),
then the concurent transition can be made. In this transition the concurrent state is updated
according to the results of the sequential execution and the thread id and security level of $i$
is recorded in the history.

The second rule covers the case in which the thread pickted by the scheduler has only the current
instruction before terminating (i.e. $\sigma.pc = \mathtt{exit}$). In the concurrent transition
the current thread id is removed from the concurrent state and everything else is like in the
first rule.

The third rule introduces the dynamic creation of new threads. In this rule the function $fresh_{l}$
\footnote{It is assumed that $fresh_l(tid) \neq fresh_{l'}(tid) \Leftrightarrow l \neq l'$.}
takes a set of thread identifiers and returns a new thread identifier at level $l$ and $\lambda_{init} : \mathcal{P}
\rightarrow \text{LocState}$ produces an initial state with the program pointer at the given program point.
If the current instruction at program point $i$ is the \texttt{start} instruction, a new thread
identifier is picked w.r.t. the security level of $i$. The program counter of the current thread
is increased by one, to step to the next instruction. The resulting concurrent state includes the
updated state of the current thread and the initial state for the new thread. The global memory
is not modified and the history is extended with the current thread id and the security level of $i$.

Based on this an evaluation relation $\Downarrow_{conc} \subseteq (\text{ConcState} \times \text{History}) \times
\text{GMemory})$ is defined by

\begin{align*}
s, h \Downarrow_{conc} \mu \Leftrightarrow \exists s', h':\ (s,h \leadsto_{conc}^* s',h') \land s'.act = \emptyset \land s'.gmem = \mu
\end{align*}

So the state $s$ evaluates according to a history $h$ to a final global memory $\mu$ iff there is a
sequence of concurrent executions that terminates (i.e. there are no active threads) and has the
global memory $\mu$. $\leadsto_{conc}^*$ is the reflexive and transitive closure of of $\leadsto_{conc}$.

$P, \mu \Downarrow_{conc} \mu'$ is a shorthand for $\langle\langle main,\lambda_{init}(1)\rangle,
\mu\rangle, \epsilon^{hist} \Downarrow_{conc} \mu'$, where $main$ is the identity of the main thread
and $\epsilon^{hist}$ the empty history.

Now we can define our goal: Noninterference. We define noninterference
in accordance to an indistinguishability relation $\sim_g$ on global memories.
Barthe et.al. state that it is not necessary, for the purpose of the paper,
to specify the definition of this relation. But to get a feel for this
relation, you can define it as: $\mu \sim_g \mu' \Leftrightarrow \mu|_{low} =
\mu'|_{low}$ where $\mu|_{low}$ projects out all high elements. Based on that
a program P is noninterfering if for all gobal memories $\mu_1, \mu_2, \mu_1'$
and $\mu_2'$ it holds that:

\begin{align*}
\mu_1 \sim_g \mu_2 \land P,\mu_1 \Downarrow_{conc} \mu_1' \land P,\mu_2 \Downarrow_{conc} \mu_2' \Rightarrow \mu_1' \sim_g \mu_2'
\end{align*}

\subsection{Type system}
\label{sec:typesystem}
The type system is the core part of the framework in the effect that it
enforces the previously defined noninterference property. Thus every
program which is typable, is noninterfering.

The type system for multithreaded programs is build up from a type system
for sequential programs for which the following assumptions hold:

\begin{enumerate}
\item We have a partial ordered set $(\text{LType}, \leq)$ of local types, with an initial
      type $\textsc{t}_{init}$
\item and typing judgments of the form $se, i \vdash_{seq} \textsc{s} \Rightarrow \textsc{t}$, where
      $\textsc{s}, \textsc{t} \in \text{LType}$, $i \in \mathcal{P}$ and se is a securirty environment.
\end{enumerate}

The intuition of the typing judgment is that if we execute the instruction at program
point $i$ w.r.t. the security environment $se$ and the current type is $\textsc{s}$. Then the
type after the execution is $\textsc{t}$.

This type system is extended by the following rules, to support multithreading:

\begin{figure}
\begin{minipage}{.5\textwidth}
\begin{align*}
\inferrule{P[i] \in \text{SeqIns} \\ se, i \vdash_{seq} \textsc{s} \Rightarrow \textsc{t}}
{se, i \vdash \textsc{s} \Rightarrow \textsc{t}}
\end{align*}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{align*}
\inferrule{P[i] = \mathtt{start}\ pc \\ se(i) \leq se(pc)}
{se, i \vdash \textsc{s} \Rightarrow \textsc{s}}
\end{align*}
\end{minipage}
\caption{Extension of the sequential typing rules.}
\label{fig:multithreaded-typing-rules}
\end{figure}

The first rule states, that sequential commands are treated as usual
and the second rule ensures, that the security level of the entry point
of the spawned thread, is lower bounded by the level of the \texttt{start}
instruction.

A program is typeable in this type system (written $\mathcal{S}, se \vdash P$),
where $\mathcal{S}$ is a function $\mathcal{S}: \mathcal{P} \rightarrow \text{LType}$
that maps a local type to every program point
and $se$ a security environment, iff $\mathcal{S}$ maps every initial program point
(including the ones of spawned threads) to $\textsc{t}_{init}$ and for every program point $j$ which is an
successor of $i$ there is a type $s \in \text{LType}$, such that $\textsc{s}$ is lower bounded
by $\mathcal{S}(j)$ and $se, i \vdash \mathcal{S}(i) \Rightarrow \textsc{s}$ holds.

\todo{Explain intuition}

\subsection{Soundness}
\label{sec:soundness}
The framework is now complete, but the proof of the connection between the
type system and the noninterference property is still outstanding. The full
proof is not part of the paper and I will only sketch the most important
parts.

The goal is to proof the following theorem:

\begin{theorem}
If the scheduler is secure and $se, \mathcal{S} \vdash P$, then P is noninterfering.
\end{theorem}

The scheduler is secure, if it is defined w.r.t. the conditions from section \ref{sec:syntaxsemantics}.

An important hypothesis to succeed in the proof of this theorem is the existence
of a \texttt{next} function. This \texttt{next} function should compute for every
high program point the first subsequent program point with a low security level. With
this function one is able to detect when a hidden thread is allowed to become visible
again.

This intuition is capture in the following properties for the function $next: \mathcal{P}
\rightharpoonup \mathcal{P}$:

\todo{Use names from paper}
\begin{enumerate}
\item $Dom(next) = \{i \in \mathcal{P} | se(i) = high \land \exists j \in \mathcal{P} . i \mapsto^* j \land se(j) \neq high\}$ \todo{use simple method of new paper?}
\item $i, j \in Dom(next) \land i \mapsto j \Rightarrow next(i) = next(j)$
\item $i \in Dom(next) \land j \not\in Dom(next) \land i \mapsto j \Rightarrow next(i) = j$
\item $j, k \in Dom(next) \land i \not\in Dom(next) \land i \mapsto j \land i \mapsto k \land j \neq k \Rightarrow next(j) = next(k)$ \todo{is there an error?}
\item $i, j \in Dom(next) \land k \not\in Dom(next) \land i \mapsto j \land i \mapsto k \land j \neq k \Rightarrow next(j) = k$
\end{enumerate}

Die domain of next just captures the high, but not always high program points (i.e. the ones
that can result in a hidden thread). The second property, states that two directly successive high
program points have the same program point in which the thread becomes visible again. The third rule
is the counterpart of the second: If a low program point follows a high program point, this low program
point is the result of the next function for the high program point.

\todo{What is wrong with property 4 (NeP3)}
\todo{What is wrong with property 5 (NeP4)}

\subsection{Instantiation}
\label{sec:instantiation}
To demonstrate how the framework can be used, it was instantiated with a simple
assembly language, which is given by the follow grammar:

\begin{align*}
instr &::= \text{binop}\ op && \text{binary operation with values from stack} \\
&|\ \text{push}\ n &&  \text{push value on the stack} \\
&|\ \text{load}\ x && \text{push value of variable on the stack} \\
&|\ \text{store}\ x && \text{store first element of the stack in $x$} \\
&|\ \text{goto}\ j\ |\ \text{ifeq}\ j && \text{un-/conditional jump to $j$} \\
&|\ \text{start}\ j && \text{create a new thread starting in $j$} \\
\end{align*}

where $op \in \{+,-,\times,/\}$, $n \in \mathbb{Z}$ and $x$ are variables. The
operational semantics are standard and not explicitly necessary for the following
instantiation, therefor they are omited.

The local states are modeled as a pair of the operand stack and the program counter. The
initial state $\lambda_{init}(pc)$ has an empty operand stack $\epsilon$ and points to
the given initial program point.

Besides this concrete language we need to define a type system to enforce noninterference
according to section \ref{sec:typesystem}. The local types are defined by a stack of security levels
$\text{LType} = \text{Stack}(\text{Level})$ and $\textsc{t}_{init}$ with the empty stack. The typing rules defined in
figure~\ref{fig:multithreaded-typing-rules} need to be extended with rules for the concrete instructions
of the assembly language. In this summary I only explain two of them, the rest follows
in a similar manner.

\begin{figure}
\begin{minipage}{.5\textwidth}
\begin{align*}
\inferrule{P[i] = \text{store}\ x \\ se(i) \sqcup k \leq \Gamma(x)}
{se, i \vdash_{seq} k :: st \Rightarrow st}
\end{align*}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{align*}
\inferrule{P[i] = \text{ifeq}\ j \\ \forall j' \in reg(i), k \leq se(j')}
{se, i \vdash_{seq} k :: st \Rightarrow lift_k(st)}
\end{align*}
\end{minipage}
\caption{Excerpt of typing rules for the assembly language.}
\label{fig:transfer-rules}
\end{figure}

The security levels in $LType$ are the security levels of the operands in the local state. To
express our security policy, we declare a function $\Gamma(x)$ that assigns to every variable
$x$ a security level. If we now want to \texttt{store} the top of the stack into the variable
$x$ one premise is that the security level of the program point ($se(i)$) \textit{and} the
security level of the value on top of the operand stack is \textit{lower or equal} to the
security level that was assigned by $\Gamma$ to the variable $x$. If this is the case the head
of $LType$ is removed. The $\sqcup$ operator is like a logical 'or', it returns the higher of
the given security values.

The rule for the branching instruction can only be used if the security level of all program
points in the control dependence region are lower bounded by the security level of the value
that is used as the condition (i.e. the top of the operand stack). The function $lift_k :
\text{Level} \rightarrow \text{Stack}(\text{Level}) \rightarrow \text{Stack}(\text{Level})$
extends $\sqcup$ to stacks of security levels. This ensures, that every program point in the control
dependence region has the same security level as the branching point.

The next step is to construct the \texttt{next} function. To make this task easy, we introduce
a source language which will be complied into the given assembly language. The source language
is defined as follows:

\begin{align*}
e ::= n\ |\ x\ |\ e\ op\ e && c ::= x\ :=\ e\ |\ c;c\ |\ \text{if}\ e\ \text{then}\ c\ \text{else}\ c\ |\ \text{while}\ e\ \text{do}\ c\ |\ \text{fork}(c)
\end{align*}

Now it is easy to define the control dependence region and the junction points for the source
language and deduce the ones for the assembly language from them. The first step is to label the
source language at the regions at risk with natural numbers:

\begin{align*}
c ::= [x\ :=\ e]^n\ |\ c;c\ |\ [\text{if}\ e\ \text{then}\ c\ \text{else}\ c]^n\ |\ [\text{while}\ e\ \text{do}\ c]^n\ |\ [\text{fork}(c)]^n
\end{align*}

According to this labels we can define the dependence regions for the source language:

\begin{definition}
The control dependence region $sregion(n)$ for a branching command $[c]^n$ in the source language is
defined as the labels inside the branching command, except for those ones that are inside a
\texttt{fork} command.
\end{definition}

Now we can define $tregion$ according to a compilation function $\mathcal{C}$. I won't define
the compilation function here, because it is not that essential how it exactly looks like.

\begin{definition}
$tregion(n)$ is defined as the set of instruction labels obtained by compiling the commands
$[c']^{n'}$ of the branching instruction $[c]^n$ of the source code with a compilation function $\mathcal{C}$.
\end{definition}

With this definition of $tregion$ in mind, it is easy to define the junction points.

\begin{definition}
The junction points are computed by a function $jun: \mathcal{P} \rightarrow \mathcal{P}$. It is defined
on all junction points $[c]^n$ in the source program and its domain is $jun(n) = max \{i\ |\ i \in tregion(n)\} + 1$.
\end{definition}

Intuitively a junction point according to this definition is the point that follows on the last instruction
that is affected by the branching instruction.

This looks familiar to the \texttt{next} function we want to define.\footnote{We could define \texttt{next} for
every instruction $i$ inside an outermost branching point $[c]^n$ as $next(i) = jun(n)$.} The part that is
missing, is the restriction to outermost branching points whose guards involves secrets.

To make this distinction a new type system is introduced. Type judgments have the form
$\vdash_\alpha [c]_{\alpha'}^n : E$, where $E$ is a function that maps labels to security
levels.\footnote{Given $E$ it is easy to define a security environment $se$. For a definition
of $E$ see \cite{Barthe06}.} $\alpha$ denotes if $c$ is \textit{part of} a branching
instruction that branches on secret ($\bullet$) or public ($\circ$) data and $\alpha'$ is the
security level of the guard \textit{in} the branching instruction.

We now take a look at the rules of this type system concerning the \texttt{if} instruction.

\begin{figure}
\begin{minipage}{.5\textwidth}
\begin{align*}
\inferrule[L-Cond]{\vdash e : L \\ \vdash_\alpha c : E \\ \vdash_\alpha c' : E}
{\vdash_\alpha [\text{if} \ e \ \text{then} \ c \ \text{else} \ c']^n_\alpha : E}
\end{align*}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{align*}
\inferrule[H-Cond]{\vdash e : H \\ \vdash_\bullet c : E \\ \vdash_\bullet c' : E}
{\vdash_\bullet [\text{if} \ e \ \text{then} \ c \ \text{else} \ c']^n_\bullet : E}
\end{align*}
\end{minipage}

\begin{align*}
\inferrule[Top-H-Cond]{\vdash e : H \\ \vdash_\bullet c : E \\
\vdash_\bullet c' : E \\ E = lift_H(E, sregion(n))}
{\vdash_\circ [\text{if} \ e \ \text{then} \ c \ \text{else} \ c']^n_\bullet : E}
\end{align*}
\caption{Typing rules for \texttt{if} on source level.}
\label{fig:typing-rules-if}
\end{figure}

The first rule \textsc{L-Cond} from Figure \ref{fig:typing-rules-if} says that if we branch on a low
guard, everything depends on the security level of $c$ and $c'$. The rule \textsc{H-Cond} covers the
case where we have a high guard, in this case the control dependence region has to be marked
high. The rule \textsc{Top-H-Cond} is the interesting one. Because of the preceding rules we can not
be part of branch with a low guard, therefore we are in the outermost high branch. The premise
$E' = lift_H(E, sregion(n))$ reads as: For all labels in the control dependence region $E$ is
defined as $E'(n) = H \sqcup E(n)$ and $E'(n) = E(n)$ for all other labels.

This type system is powerful enough to prevent explicit and implicit flows and can therefor
replace the type system defined previously.

With this type system in mind, we can now define our \texttt{next} function.

\begin{definition}
For every branching point $c$ in the source program such that $\vdash_\circ [c]_\bullet^n$, the next function
is defined as $\forall k \in tregion(n) .\ next(k) = jun(n)$.
\end{definition}

The proof that this definition fulfills the properties from section \ref{sec:soundness} and all other
proofs can be found in \cite{Barthe09}.

Now the instantiation of the framework is complete, except for the scheduler which was left unspecified
in the paper.

\section{Comparison with other approaches/further work}
\label{sec:furtherwork}

\bibliography{bibliography}

\end{document}
